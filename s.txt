=== ./src/database.rs ===
// src/database.rs - Using runtime queries instead of compile-time macros
use crate::models::{ApiResponse, EvalResult};
use sqlx::{sqlite::SqlitePoolOptions, Row, SqlitePool};
use std::path::PathBuf;

pub async fn init_db() -> Result<SqlitePool, sqlx::Error> {
    let db_path = get_db_path()?;
    let db_url = format!("sqlite:{}", db_path.to_str().unwrap());

    if let Some(parent) = db_path.parent() {
        std::fs::create_dir_all(parent)
            .map_err(|e| sqlx::Error::Io(e))?;
    }

    let pool = SqlitePoolOptions::new()
        .max_connections(5)
        .connect(&db_url)
        .await?;

    // Run migrations from the migrations directory
    sqlx::migrate!("./migrations")
        .run(&pool)
        .await?;

    Ok(pool)
}

fn get_db_path() -> Result<PathBuf, sqlx::Error> {
    let db_url = std::env::var("DATABASE_URL")
        .map_err(|_| sqlx::Error::Configuration("DATABASE_URL must be set".into()))?;
    
    let db_path_str = db_url.strip_prefix("sqlite:").ok_or_else(|| {
        sqlx::Error::Configuration("DATABASE_URL must start with 'sqlite:'".into())
    })?;
    
    Ok(PathBuf::from(db_path_str))
}

pub async fn save_evaluation(pool: &SqlitePool, response: &ApiResponse) -> Result<(), sqlx::Error> {
    let id = &response.id;
    let status = response.status.to_string();

    let (
        model,
        prompt,
        model_output,
        expected,
        judge_model,
        judge_verdict,
        judge_reasoning,
        error_message,
        created_at,
    ) = match &response.result {
            EvalResult::Success(res) => (
                Some(res.model.clone()),
                Some(res.prompt.clone()),
                Some(res.model_output.clone()),
                res.expected.clone(),
                res.judge_result.as_ref().map(|j| j.judge_model.clone()),
                res.judge_result.as_ref().map(|j| j.verdict.to_string()),
                res.judge_result.as_ref().map(|j| j.reasoning.clone()),
                None,
                Some(res.timestamp.clone()),
            ),
            EvalResult::Error(err) => (
                None,
                None,
                None,
                None,
                None,
                None,
                None,
                Some(err.message.clone()),
                None,
            ),
        };

    let created_at_str = created_at.unwrap_or_else(|| chrono::Utc::now().to_rfc3339());

    // Use runtime query instead of compile-time macro
    sqlx::query(
        r#"
        INSERT INTO evaluations (id, status, model, prompt, model_output, expected, judge_model, judge_verdict, judge_reasoning, error_message, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        "#
    )
    .bind(id)
    .bind(&status)
    .bind(&model)
    .bind(&prompt)
    .bind(&model_output)
    .bind(&expected)
    .bind(&judge_model)
    .bind(&judge_verdict)
    .bind(&judge_reasoning)
    .bind(&error_message)
    .bind(&created_at_str)
    .execute(pool)
    .await?;

    Ok(())
}

pub async fn get_all_evaluations(pool: &SqlitePool) -> Result<Vec<HistoryEntry>, sqlx::Error> {
    let rows = sqlx::query(
        r#"
        SELECT id, status, model, prompt, model_output, expected, judge_model, judge_verdict, judge_reasoning, error_message, created_at
        FROM evaluations
        ORDER BY created_at DESC
        "#
    )
    .fetch_all(pool)
    .await?;

    Ok(rows.into_iter().map(|row| HistoryEntry {
        id: row.get(0),
        status: row.get(1),
        model: row.get(2),
        prompt: row.get(3),
        model_output: row.get(4),
        expected: row.get(5),
        judge_model: row.get(6),
        judge_verdict: row.get(7),
        judge_reasoning: row.get(8),
        error_message: row.get(9),
        created_at: row.get(10),
    }).collect())
}

#[derive(serde::Serialize, Clone)]
pub struct HistoryEntry {
    pub id: String,
    pub status: Option<String>,
    pub model: Option<String>,
    pub prompt: Option<String>,
    pub model_output: Option<String>,
    pub expected: Option<String>,
    pub judge_model: Option<String>,
    pub judge_verdict: Option<String>,
    pub judge_reasoning: Option<String>,
    pub error_message: Option<String>,
    pub created_at: String,
}
=== ./src/runner.rs ===
// src/runner.rs
use crate::config::{AppConfig, EvalConfig};
use crate::errors::{EvalError, Result};
use reqwest::Client;
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::time::Instant;

#[derive(Deserialize)]
struct GeminiResponse {
    candidates: Vec<Candidate>,
}

#[derive(Deserialize)]
struct Candidate {
    content: Content,
}

#[derive(Deserialize)]
struct Content {
    parts: Vec<Part>,
}

#[derive(Deserialize)]
struct Part {
    text: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct EvalResult {
    pub model: String,
    pub prompt: String,
    pub model_output: String,
    pub expected: Option<String>,
    pub judge_result: Option<JudgeResult>,
    pub timestamp: String,
    pub latency_ms: u64,
    pub judge_latency_ms: Option<u64>,
    pub total_latency_ms: u64,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct JudgeResult {
    pub judge_model: String,
    pub verdict: JudgeVerdict,
    pub reasoning: Option<String>,
    pub confidence: Option<f32>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub enum JudgeVerdict {
    Pass,
    Fail,
    Uncertain,
}

impl std::fmt::Display for JudgeVerdict {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            JudgeVerdict::Pass => write!(f, "Pass"),
            JudgeVerdict::Fail => write!(f, "Fail"),
            JudgeVerdict::Uncertain => write!(f, "Uncertain"),
        }
    }
}

/// Calls the Gemini API with a given prompt and returns the model's response text and latency.
async fn call_gemini_api(
    client: &Client,
    api_base: &str,
    api_key: &str,
    model: &str,
    prompt: &str,
) -> Result<(String, u64)> {
    let url = format!(
        "{}/v1beta/models/{}:generateContent",
        api_base.trim_end_matches('/'),
        model
    );

    println!("üì° Calling: {} with model: {}", url, model);

    let body = json!({
        "contents": [{"parts": [{"text": prompt}]}]
    });

    let start = Instant::now();
    
    let resp = client
        .post(&url)
        .header("x-goog-api-key", api_key)
        .json(&body)
        .send()
        .await?;

    let status = resp.status();
    let latency_ms = start.elapsed().as_millis() as u64;
    
    println!("üì• Response status: {} ({}ms)", status, latency_ms);

    if !status.is_success() {
        let error_body = resp.text().await.unwrap_or_else(|_| "Could not read error body".to_string());
        return Err(EvalError::ApiError {
            status: status.as_u16(),
            body: error_body,
        });
    }

    let response_json: Value = resp.json().await?;

    if let Some(error) = response_json.get("error") {
        return Err(EvalError::ApiResponse(error.to_string()));
    }

    let output = response_json
        .get("candidates")
        .and_then(|c| c.get(0))
        .and_then(|c| c.get("content"))
        .and_then(|c| c.get("parts"))
        .and_then(|p| p.get(0))
        .and_then(|p| p.get("text"))
        .and_then(|t| t.as_str())
        .ok_or_else(|| EvalError::UnexpectedResponse(response_json.to_string()))?;

    if output.is_empty() {
        return Err(EvalError::EmptyResponse);
    }

    Ok((output.to_string(), latency_ms))
}

/// Parse judge response to extract verdict and reasoning
fn parse_judge_response(response: &str) -> JudgeResult {
    let response_lower = response.to_lowercase();
    
    // Try to extract structured response if available
    let verdict = if response_lower.contains("verdict: pass") || 
                     (response_lower.starts_with("yes") || response_lower.contains("yes, they")) {
        JudgeVerdict::Pass
    } else if response_lower.contains("verdict: fail") || 
              (response_lower.starts_with("no") || response_lower.contains("no, they")) {
        JudgeVerdict::Fail
    } else {
        JudgeVerdict::Uncertain
    };

    // Extract reasoning if present (look for lines after the verdict)
    let reasoning = if response.len() > 20 {
        Some(response.to_string())
    } else {
        None
    };

    JudgeResult {
        judge_model: "unknown".to_string(),
        verdict,
        reasoning,
        confidence: None,
    }
}

/// Enhanced judge prompt with better structure
fn create_judge_prompt(expected: &str, actual: &str, criteria: Option<&str>) -> String {
    let base_criteria = criteria.unwrap_or(
        "The outputs should convey the same core meaning, even if phrased differently."
    );

    format!(
        r#"You are an expert evaluator comparing two text outputs.

EVALUATION CRITERIA:
{}

EXPECTED OUTPUT:
{}

ACTUAL OUTPUT:
{}

INSTRUCTIONS:
1. Carefully compare both outputs
2. Consider semantic equivalence, not just exact wording
3. Provide your verdict as the first line: "Verdict: PASS" or "Verdict: FAIL"
4. Then explain your reasoning in 2-3 sentences

Your evaluation:"#,
        base_criteria,
        expected,
        actual
    )
}

/// Run a single eval with comprehensive LLM-as-a-judge evaluation
pub async fn run_eval(
    app: &AppConfig, 
    eval: &EvalConfig, 
    client: &Client
) -> Result<EvalResult> {
    let eval_start = Instant::now();
    let separator = "=".repeat(60);
    println!("\n{}", separator);
    println!("üéØ Starting evaluation for model: {}", eval.model);
    println!("{}\n", separator);

    // Step 1: Call the target model
    println!("üìù Prompt: {}", eval.prompt);
    
    let (model_output, latency_ms) = call_gemini_api(
        client,
        &app.api_base,
        &app.api_key,
        &eval.model,
        &eval.prompt,
    )
    .await
    .map_err(|e| {
        eprintln!("‚ùå Model failed: {}", e);
        EvalError::ModelFailure {
            model: eval.model.clone(),
        }
    })?;

    println!("\n‚úÖ Model Output ({}ms):\n{}\n", latency_ms, model_output);

    // Step 2: Run judge evaluation if expected output provided
    let mut judge_latency_ms = None;
    let judge_result = if let (Some(expected), Some(judge_model)) = 
        (&eval.expected, &eval.judge_model) {
        
        println!("‚öñÔ∏è  Running judge evaluation with model: {}", judge_model);
        
        let judge_prompt = create_judge_prompt(
            expected,
            &model_output,
            eval.criteria.as_deref()
        );

        match call_gemini_api(
            client,
            &app.api_base,
            &app.api_key,
            judge_model,
            &judge_prompt,
        )
        .await
        {
            Ok((judge_response, judge_latency)) => {
                judge_latency_ms = Some(judge_latency);
                println!("\n‚öñÔ∏è  Judge Response ({}ms):\n{}\n", judge_latency, judge_response);
                
                let mut result = parse_judge_response(&judge_response);
                result.judge_model = judge_model.clone();
                
                match result.verdict {
                    JudgeVerdict::Pass => println!("‚úÖ VERDICT: PASS"),
                    JudgeVerdict::Fail => println!("‚ùå VERDICT: FAIL"),
                    JudgeVerdict::Uncertain => println!("‚ö†Ô∏è  VERDICT: UNCERTAIN"),
                }
                
                Some(result)
            }
            Err(e) => {
                let judge_error = EvalError::JudgeFailure {
                    model: judge_model.clone(),
                    source: Box::new(e),
                };
                eprintln!("‚ö†Ô∏è  Judge evaluation failed: {}", judge_error);
                None
            }
        }
    } else {
        println!("‚ÑπÔ∏è  No judge evaluation (no expected output or judge model specified)");
        None
    };

    let total_latency_ms = eval_start.elapsed().as_millis() as u64;
    println!("‚è±Ô∏è  Total evaluation time: {}ms", total_latency_ms);
    println!("\n{}\n", separator);

    Ok(EvalResult {
        model: eval.model.clone(),
        prompt: eval.prompt.clone(),
        model_output,
        expected: eval.expected.clone(),
        judge_result,
        timestamp: chrono::Utc::now().to_rfc3339(),
        latency_ms,
        judge_latency_ms,
        total_latency_ms,
    })
}

/// Run multiple evals and aggregate results
pub async fn run_batch_evals(
    app: &AppConfig,
    evals: Vec<EvalConfig>,
    client: &Client,
) -> Vec<Result<EvalResult>> {
    let mut results = Vec::new();
    let batch_start = Instant::now();
    
    for (idx, eval) in evals.iter().enumerate() {
        println!("\nüîÑ Running eval {}/{}", idx + 1, evals.len());
        let result = run_eval(app, eval, client).await;
        results.push(result);
        
        // Add small delay between requests to avoid rate limiting
        if idx < evals.len() - 1 {
            tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
        }
    }
    
    let batch_total_ms = batch_start.elapsed().as_millis() as u64;
    println!("\nüìä Batch completed in {}ms", batch_total_ms);
    
    results
}
=== ./src/errors.rs ===
// src/errors.rs
use thiserror::Error;

#[derive(Error, Debug)]
#[allow(dead_code)]
pub enum EvalError {
    #[error("Failed to read file: {0}")]
    FileRead(#[from] std::io::Error),

    #[error("Failed to parse TOML config: {0}")]
    TomlParse(#[from] toml::de::Error),

    #[error("Failed to parse JSON config: {0}")]
    JsonParse(#[from] serde_json::Error),

    #[error("HTTP request failed: {0}")]
    Request(#[from] reqwest::Error),

    #[error("API request failed with status {status}: {body}")]
    ApiError { status: u16, body: String },

    #[error("API returned an error: {0}")]
    ApiResponse(String),

    #[error("Unexpected response structure: {0}")]
    UnexpectedResponse(String),

    #[error("Received empty text response from model")]
    EmptyResponse,

    #[error("Model '{model}' failed to respond")]
    ModelFailure { model: String },

    #[error("Judge model '{model}' failed: {source}")]
    JudgeFailure {
        model: String,
        #[source]
        source: Box<EvalError>,
    },
}

pub type Result<T> = std::result::Result<T, EvalError>;

=== ./src/main.rs ===
mod api;
mod config;
mod errors;
mod runner;
mod models;
mod database;

use actix_web::{middleware, App, HttpServer};
use actix_files as fs;
use actix_cors::Cors;
use api::{configure_routes, AppState};

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    // Load .env file - fail loudly if it doesn't exist
    if let Err(e) = dotenv::dotenv() {
        eprintln!("‚ö†Ô∏è  Warning: Could not load .env file: {}", e);
        eprintln!("   Make sure DATABASE_URL is set in your environment");
    }
    
    // Debug: Check if DATABASE_URL is set
    match std::env::var("DATABASE_URL") {
        Ok(url) => println!("‚úÖ DATABASE_URL set to: {}", url),
        Err(_) => eprintln!("‚ùå DATABASE_URL not set!"),
    }
    
    env_logger::init_from_env(env_logger::Env::new().default_filter_or("info"));
    
    let app_config = config::AppConfig::from_file("src/config.toml")
        .expect("Failed to load config");
    
    let state = AppState::new(app_config).await;
    
    println!("üöÄ Starting server at http://127.0.0.1:8080");
    println!("üìä Frontend available at http://127.0.0.1:8080");
    println!("üîå API available at http://127.0.0.1:8080/api/v1");
    
    HttpServer::new(move || {
        let cors = Cors::permissive();
        
        App::new()
            .app_data(actix_web::web::Data::new(state.clone()))
            .wrap(cors)
            .wrap(middleware::Logger::default())
            .configure(configure_routes)
            .service(fs::Files::new("/static", "./static").show_files_listing())
            .service(fs::Files::new("/", "./static").index_file("index.html"))
    })
    .bind(("127.0.0.1", 8080))?
    .run()
    .await
}
=== ./src/config.rs ===
// src/config.rs
use std::fs;
use serde::Deserialize;
use crate::errors::Result;

/// High-level application configuration.
#[derive(Debug, Deserialize, Clone)]
pub struct AppConfig {
    /// Base API URL for Gemini
    pub api_base: String,
    /// API key for Gemini
    pub api_key: String,
    /// List of JSON eval files
    #[serde(default)]
    pub evals: Vec<String>,
}

/// Contains all the information needed to run one prompt against a model
#[derive(Deserialize, Debug, Clone)]
pub struct EvalConfig {
    /// The model to evaluate
    pub model: String,
    
    /// The prompt to send to the model
    pub prompt: String,
    
    /// Expected output for comparison (optional)
    #[serde(default)]
    pub expected: Option<String>,
    
    /// Judge model for LLM-as-a-judge evaluation (optional)
    #[serde(default)]
    pub judge_model: Option<String>,
    
    /// Custom evaluation criteria (optional)
    /// If not provided, default semantic equivalence criteria will be used
    #[serde(default)]
    pub criteria: Option<String>,
    
    /// Tags for organizing evals
    #[serde(default)]
    pub tags: Vec<String>,
    
    /// Metadata for the eval
    #[serde(default)]
    pub metadata: Option<serde_json::Value>,
}

impl AppConfig {
    pub fn from_file(path: &str) -> Result<Self> {
        let data = fs::read_to_string(path)?;
        let cfg: AppConfig = toml::from_str(&data)?;
        Ok(cfg)
    }
}

impl EvalConfig {
    /// Load a single EvalConfig from a JSON file
    pub fn from_file(path: &str) -> Result<Self> {
        let data = fs::read_to_string(path)?;
        let cfg: EvalConfig = serde_json::from_str(&data)?;
        Ok(cfg)
    }
    
    /// Load multiple EvalConfigs from a JSON array file
    pub fn batch_from_file(path: &str) -> Result<Vec<Self>> {
        let data = fs::read_to_string(path)?;
        let configs: Vec<EvalConfig> = serde_json::from_str(&data)?;
        Ok(configs)
    }
}
=== ./src/models.rs ===
// src/models.rs
use crate::runner;
use serde::Serialize;

#[derive(Serialize, Clone)]
pub enum EvalResult {
    Success(runner::EvalResult),
    Error(ApiError),
}

#[derive(Serialize, Clone, Debug)]
pub struct ApiError {
    pub message: String,
}

#[derive(Serialize, Clone)]
pub struct ApiResponse {
    pub id: String,
    pub status: String,
    pub result: EvalResult,
}
=== ./src/api/handlers.rs ===
// src/api/handlers.rs
mod health;
mod evals;
mod experiments;
mod history;

pub use health::health_check;
pub use evals::{run_eval, run_batch, get_eval, get_status, get_history};
pub use experiments::{create_experiment, get_experiment};

=== ./src/api/handlers/history.rs ===
use actix_web::{web, HttpResponse, Result};
use serde::Serialize;
use crate::api::AppState;

#[derive(Serialize)]
pub struct HistoryResponse {
    pub results: Vec<crate::database::HistoryEntry>,
}

pub async fn get_history(
    state: web::Data<AppState>,
) -> Result<HttpResponse> {
    match state.db_pool.as_ref() {
        Some(pool) => {
            match crate::database::get_all_evaluations(pool).await {
                Ok(results) => Ok(HttpResponse::Ok().json(HistoryResponse { results })),
                Err(e) => {
                    eprintln!("Database error: {}", e);
                    Ok(HttpResponse::InternalServerError().json(serde_json::json!({
                        "error": "Failed to fetch history"
                    })))
                }
            }
        }
        None => Ok(HttpResponse::InternalServerError().json(serde_json::json!({
            "error": "Database not initialized"
        }))),
    }
}

=== ./src/api/handlers/health.rs ===
// src/api/handlers/health.rs
use actix_web::{HttpResponse, Result};
use serde_json::json;

pub async fn health_check() -> Result<HttpResponse> {
    Ok(HttpResponse::Ok().json(json!({
        "status": "healthy",
        "service": "eval-api",
        "version": env!("CARGO_PKG_VERSION")
    })))
}

=== ./src/api/handlers/experiments.rs ===
// src/api/handlers/experiments.rs
use actix_web::{web, HttpResponse, Result};
use serde::{Deserialize, Serialize};
use serde_json::json;
use uuid::Uuid;

#[derive(Deserialize)]
pub struct CreateExperimentRequest {
    pub name: String,
    pub description: Option<String>,
    pub eval_ids: Vec<String>,
}

#[derive(Serialize)]
pub struct ExperimentResponse {
    pub id: String,
    pub name: String,
    pub status: String,
    pub created_at: String,
}

pub async fn create_experiment(
    req: web::Json<CreateExperimentRequest>,
) -> Result<HttpResponse> {
    let experiment_id = Uuid::new_v4().to_string();
    
    Ok(HttpResponse::Created().json(ExperimentResponse {
        id: experiment_id,
        name: req.name.clone(),
        status: "created".to_string(),
        created_at: chrono::Utc::now().to_rfc3339(),
    }))
}

pub async fn get_experiment(path: web::Path<String>) -> Result<HttpResponse> {
    let experiment_id = path.into_inner();
    
    Ok(HttpResponse::Ok().json(json!({
        "id": experiment_id,
        "name": "Mock Experiment",
        "status": "completed",
        "results": {
            "total_evals": 10,
            "passed": 8,
            "failed": 2
        }
    })))
}

=== ./src/api/handlers/evals.rs ===
// src/api/handlers/evals.rs
use actix_web::{web, HttpResponse, Result};
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use crate::api::AppState;
use crate::config::EvalConfig;
use crate::runner;
use serde_json::json;

#[derive(Clone, Deserialize)]
pub struct RunEvalRequest {
    pub model: String,
    pub prompt: String,
    pub expected: Option<String>,
    pub judge_model: Option<String>,
    pub criteria: Option<String>,
}

#[derive(Clone, Deserialize)]
pub struct BatchEvalRequest {
    pub evals: Vec<RunEvalRequest>,
}

#[derive(Serialize)]
pub struct EvalResponse {
    pub id: String,
    pub status: String,
    pub result: Option<runner::EvalResult>,
    pub error: Option<String>,
}

#[derive(Serialize)]
pub struct BatchEvalResponse {
    pub batch_id: String,
    pub status: String,
    pub total: usize,
    pub completed: usize,
    pub passed: usize,
    pub failed: usize,
    pub results: Vec<EvalResponse>,
}

impl From<RunEvalRequest> for EvalConfig {
    fn from(req: RunEvalRequest) -> Self {
        EvalConfig {
            model: req.model,
            prompt: req.prompt,
            expected: req.expected,
            judge_model: req.judge_model,
            criteria: req.criteria,
            tags: Vec::new(),
            metadata: None,
        }
    }
}

pub async fn run_eval(
    state: web::Data<AppState>,
    req: web::Json<RunEvalRequest>,
) -> Result<HttpResponse> {
    let eval_id = Uuid::new_v4().to_string();
    let eval_config: EvalConfig = req.into_inner().into();

    match runner::run_eval(&state.config, &eval_config, &state.client).await {
        Ok(result) => {
            let status = if let Some(judge) = &result.judge_result {
                match judge.verdict {
                    runner::JudgeVerdict::Pass => "passed",
                    runner::JudgeVerdict::Fail => "failed",
                    runner::JudgeVerdict::Uncertain => "uncertain",
                }
            } else {
                "completed"
            };

            let response = EvalResponse {
                id: eval_id.clone(),
                status: status.to_string(),
                result: Some(result.clone()),
                error: None,
            };

            // Save to database
            if let Some(pool) = state.db_pool.as_ref() {
                let api_response = crate::models::ApiResponse {
                    id: eval_id,
                    status: status.to_string(),
                    result: crate::models::EvalResult::Success(result),
                };
                if let Err(e) = crate::database::save_evaluation(pool, &api_response).await {
                    log::error!("Failed to save evaluation to database: {}", e);
                }
            }

            Ok(HttpResponse::Ok().json(response))
        }
        Err(e) => {
            let error_string = e.to_string();
            Ok(HttpResponse::InternalServerError().json(EvalResponse {
                id: eval_id,
                status: "error".to_string(),
                result: None,
                error: Some(error_string),
            }))
        }
    }
}

pub async fn run_batch(
    state: web::Data<AppState>,
    req: web::Json<BatchEvalRequest>,
) -> Result<HttpResponse> {
    let batch_id = Uuid::new_v4().to_string();
    let total = req.evals.len();
    let req_body = req.into_inner();

    let eval_configs: Vec<EvalConfig> = req_body.evals.into_iter().map(Into::into).collect();

    let results = runner::run_batch_evals(
        &state.config,
        eval_configs,
        &state.client,
    ).await;

    let mut responses = Vec::new();
    let mut completed = 0;
    let mut passed = 0;
    let mut failed = 0;

    for result in results {
        let eval_id = Uuid::new_v4().to_string();
        
        match result {
            Ok(eval_result) => {
                completed += 1;
                
                let status = if let Some(judge) = &eval_result.judge_result {
                    match judge.verdict {
                        runner::JudgeVerdict::Pass => {
                            passed += 1;
                            "passed"
                        }
                        runner::JudgeVerdict::Fail => {
                            failed += 1;
                            "failed"
                        }
                        runner::JudgeVerdict::Uncertain => "uncertain",
                    }
                } else {
                    "completed"
                };

                responses.push(EvalResponse {
                    id: eval_id,
                    status: status.to_string(),
                    result: Some(eval_result),
                    error: None,
                });
            }
            Err(e) => {
                failed += 1;
                responses.push(EvalResponse {
                    id: eval_id,
                    status: "error".to_string(),
                    result: None,
                    error: Some(e.to_string()),
                });
            }
        }
    }

    Ok(HttpResponse::Ok().json(BatchEvalResponse {
        batch_id,
        status: "completed".to_string(),
        total,
        completed,
        passed,
        failed,
        results: responses,
    }))
}

pub async fn get_eval(path: web::Path<String>) -> Result<HttpResponse> {
    let eval_id = path.into_inner();
    
    Ok(HttpResponse::Ok().json(json!({
        "id": eval_id,
        "status": "completed",
        "message": "This endpoint would return stored eval results"
    })))
}

pub async fn get_status(path: web::Path<String>) -> Result<HttpResponse> {
    let eval_id = path.into_inner();
    
    Ok(HttpResponse::Ok().json(json!({
        "id": eval_id,
        "status": "completed",
        "progress": 100
    })))
}

#[derive(Serialize)]
pub struct HistoryResponse {
    pub results: Vec<crate::database::HistoryEntry>,
}

pub async fn get_history(state: web::Data<AppState>) -> Result<HttpResponse> {
    if let Some(pool) = state.db_pool.as_ref() {
        match crate::database::get_all_evaluations(pool).await {
            Ok(history) => Ok(HttpResponse::Ok().json(HistoryResponse { results: history })),
            Err(e) => {
                log::error!("Failed to fetch evaluation history: {}", e);
                Ok(HttpResponse::InternalServerError()
                    .json(json!({"error": "Failed to load history from database."})))
            }
        }
    } else {
        Ok(HttpResponse::Ok().json(HistoryResponse { results: vec![] }))
    }
}
=== ./src/api/routes.rs ===
// src/api/routes.rs
use actix_web::web;
use super::handlers;

pub fn configure_routes(cfg: &mut web::ServiceConfig) {
    cfg.service(
        web::scope("/api/v1")
            .route("/health", web::get().to(handlers::health_check))
            .service(
                web::scope("/evals")
                    .route("/run", web::post().to(handlers::run_eval))
                    .route("/batch", web::post().to(handlers::run_batch))
                    .route("/history", web::get().to(handlers::get_history))
                    .route("/{id}", web::get().to(handlers::get_eval))
                    .route("/{id}/status", web::get().to(handlers::get_status))
            )
            .service(
                web::scope("/experiments")
                    .route("", web::post().to(handlers::create_experiment))
                    .route("/{id}", web::get().to(handlers::get_experiment))
            )
    );
}


=== ./src/api/state.rs ===
use crate::config::AppConfig;
use reqwest::Client;
use sqlx::SqlitePool;
use std::sync::Arc;

#[derive(Clone)]
pub struct AppState {
    pub config: Arc<AppConfig>,
    pub client: Client,
    pub db_pool: Arc<Option<SqlitePool>>,
}

impl AppState {
    pub async fn new(config: AppConfig) -> Self {
        let db_pool = crate::database::init_db()
            .await
            .ok();

        Self {
            config: Arc::new(config),
            client: Client::new(),
            db_pool: Arc::new(db_pool),
        }
    }
}
=== ./src/api/mod.rs ===
pub mod handlers;
pub mod routes;

pub use routes::configure_routes;

use crate::config::AppConfig;
use crate::database;
use reqwest::Client;
use sqlx::SqlitePool;

#[derive(Clone)]
pub struct AppState {
    pub config: AppConfig,
    pub client: Client,
    pub db_pool: Option<SqlitePool>,
}

impl AppState {
    pub async fn new(config: AppConfig) -> Self {
        let db_pool = match database::init_db().await {
            Ok(pool) => Some(pool),
            Err(e) => {
                log::error!("Failed to initialize database: {}", e);
                None
            }
        };
        Self { config, client: Client::new(), db_pool }
    }
}
